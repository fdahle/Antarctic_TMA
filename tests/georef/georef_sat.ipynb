{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa5dd78b3114b43"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_id = \"CA214732V0029\"\n",
    "save_image = False\n",
    "overwrite = False\n",
    "\n",
    "output_fld = \"/data_1/ATM/data_1/georef\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Check if the image is already geo-referenced</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define the path to processed images\n",
    "csv_path = output_fld + \"/sat_processed_images.csv\"\n",
    "\n",
    "if save_image:\n",
    "    # load processed images as dict\n",
    "    processed_images = pd.read_csv(csv_path, delimiter=\";\")\n",
    "    processed_images.set_index('id', inplace=True)\n",
    "    processed_images = processed_images.to_dict(orient='index')\n",
    "\n",
    "    # check if image is already geo-referenced\n",
    "    if processed_images.get(img_id, {}).get('status') == \"georeferenced\" and not overwrite:\n",
    "        print(f\"{img_id} already processed\")\n",
    "        exit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Load Image</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9522, 10140)\n"
     ]
    }
   ],
   "source": [
    "import src.load.load_image as ld\n",
    "\n",
    "path_data_fld = \"/data_1/ATM/data_1/aerial/TMA/downloaded\"\n",
    "\n",
    "# load image to geo-reference\n",
    "image = ld.load_image(path_data_fld + f\"/{img_id}.tif\")\n",
    "\n",
    "print(image.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b318989a3fd394d",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Extract geo-referencing data</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth: 334.9602\n",
      "Month: 12\n",
      "Approx footprint: POLYGON((-2398563.0512240864 1295625.1957908687,-2413972.8442091313 1262638.6312240863,-2446959.4087759135 1278048.4242091314,-2431549.6157908686 1311034.9887759138,-2398563.0512240864 1295625.1957908687))\n"
     ]
    }
   ],
   "source": [
    "import src.base.connect_to_database as ctd\n",
    "import src.base.modify_csv as mc\n",
    "\n",
    "conn = ctd.establish_connection()\n",
    "\n",
    "sql_string = f\"SELECT * FROM images WHERE image_id='{img_id}'\"\n",
    "data = ctd.execute_sql(sql_string, conn)\n",
    "\n",
    "azimuth = data.iloc[0]['azimuth']\n",
    "month = data.iloc[0]['date_month']\n",
    "\n",
    "azimuth = 360 - azimuth + 90\n",
    "\n",
    "print(\"Azimuth:\", azimuth)\n",
    "print(\"Month:\", month)\n",
    "\n",
    "sql_string_approx = f\"SELECT ST_AsText(footprint_approx) AS footprint_approx FROM images_extracted WHERE image_id='{img_id}'\"\n",
    "data_approx = ctd.execute_sql(sql_string_approx, conn)\n",
    "footprint_approx = data_approx.iloc[0]['footprint_approx']\n",
    "\n",
    "print(\"Approx footprint:\",footprint_approx)\n",
    "\n",
    "if footprint_approx is None:\n",
    "    processed_images[img_id] = {\"method\": \"sat\", \"status\": \"missing_data\",\n",
    "                                  \"reason\": \"approx_footprint\", \"time\":\"\"}\n",
    "    mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()\n",
    "\n",
    "elif azimuth is None:\n",
    "    processed_images[img_id] = {\"method\": \"sat\", \"status\": \"missing_data\",\n",
    "                                  \"reason\": \"azimuth\", \"time\":\"\"}\n",
    "    mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "937eb40f9717a45e",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Create Mask</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (None, None), 2: (None, None), 3: (None, None), 4: (None, None)}\n",
      "[[223, 6052, 611, 9143], [174, 5155, 323, 5626], [0, 3218, 560, 4340], [0, 2043, 219, 2758]]\n"
     ]
    }
   ],
   "source": [
    "import src.base.create_mask as cm\n",
    "import src.base.modify_csv as mc\n",
    "\n",
    "import src.display.display_images as di\n",
    "\n",
    "sql_string_fid_marks = f\"SELECT * FROM images_fid_points WHERE image_id='{img_id}'\"\n",
    "data_fid_marks = ctd.execute_sql(sql_string_fid_marks, conn)\n",
    "\n",
    "sql_string_extracted = f\"SELECT * FROM images_extracted WHERE image_id='{img_id}'\"\n",
    "data_extracted = ctd.execute_sql(sql_string_extracted, conn)\n",
    "\n",
    "# Get the fid marks for the specific image_id\n",
    "fid_marks_row = data_fid_marks.loc[data_fid_marks['image_id'] == img_id].squeeze()\n",
    "\n",
    "# Create fid mark dict using dictionary comprehension\n",
    "fid_dict = {i: (fid_marks_row[f'fid_mark_{i}_x'], fid_marks_row[f'fid_mark_{i}_y']) for i in range(1, 5)}\n",
    "\n",
    "# get the text boxes of the image\n",
    "text_string = data_extracted.loc[data_extracted['image_id'] == img_id]['text_bbox'].iloc[0]\n",
    "\n",
    "if len(text_string) > 0 and \"[\" not in text_string:\n",
    "    text_string = \"[\" + text_string + \"]\"\n",
    "\n",
    "# create text-boxes list\n",
    "text_boxes = [list(group) for group in eval(text_string.replace(\";\", \",\"))]\n",
    "\n",
    "print(fid_dict)\n",
    "\n",
    "# load the mask\n",
    "mask = cm.create_mask(image, fid_dict, text_boxes, use_default_fiducials=True)\n",
    "\n",
    "if mask is None:\n",
    "    processed_images[img_id] = {\"method\": \"sat\", \"status\": \"missing_data\",\n",
    "                                  \"reason\": \"mask\", \"time\":\"\"}\n",
    "    mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()\n",
    "\n",
    "\n",
    "di.display_images([image, mask])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e495b60f07b88d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Geo-reference the image</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geo-reference image by satellite\n",
      "Adjusted image resolution with zoom-factor (0.3748, 0.3662)\n",
      "Adjusted image resolution with zoom-factor (0.3748, 0.3662)\n",
      "Locate image position\n",
      "  Check tile 1 (Coords: [-32273, -32266], Order 1)\n",
      "  28 points were found in this tile.\n",
      "  Check tile 2 (Coords: [-32273, 0], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 3 (Coords: [-32273, 32266], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 4 (Coords: [0, -32266], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 5 (Coords: [0, 32266], Order 1)\n",
      "  79 points were found in this tile.\n",
      "  Check tile 6 (Coords: [32273, -32266], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 7 (Coords: [32273, 0], Order 1)\n",
      "  111 points were found in this tile.\n",
      "  Check tile 8 (Coords: [32273, 32266], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 9 (Coords: [-64546, -64532], Order 2)\n",
      "  66 points were found in this tile.\n",
      "  Check tile 10 (Coords: [-64546, -32266], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 11 (Coords: [-64546, 0], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 12 (Coords: [-64546, 32266], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 13 (Coords: [-64546, 64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 14 (Coords: [-32273, -64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 15 (Coords: [-32273, 64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 16 (Coords: [0, -64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 17 (Coords: [0, 64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 18 (Coords: [32273, -64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 19 (Coords: [32273, 64532], Order 2)\n",
      "  28 points were found in this tile.\n",
      "  Check tile 20 (Coords: [64546, -64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 21 (Coords: [64546, -32266], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 22 (Coords: [64546, 0], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 23 (Coords: [64546, 32266], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 24 (Coords: [64546, 64532], Order 2)\n",
      "  0 points were found in this tile.\n",
      "Best tile is [32273, 0] with 111 tie-points (0.234)\n",
      "Tweak image position\n",
      "  Tweak image (1/10) with (-259, -1227)\n",
      "  120 points found in tweak 1 of 10\n",
      "  Tweak image (2/10) with (-625, -958)\n",
      "  0 points found in tweak 2 of 10\n",
      "  Points not increasing (0 < 120)\n",
      "  Tweak image (3/10) with (0, 0)\n",
      "  0 points found in tweak 3 of 10\n",
      "  Points not increasing (0 < 120)\n",
      "  Break the loop\n",
      "Tweaking finished with 120 tie-points\n",
      "8 outliers removed with RANSAC\n",
      "Image successfully geo-referenced\n"
     ]
    }
   ],
   "source": [
    "import src.base.modify_csv as mc\n",
    "\n",
    "import src.georef.georef_sat as gs\n",
    "\n",
    "georefSat = gs.GeorefSatellite(min_tps_final=25,\n",
    "                               enhance_image=False, locate_image=True, tweak_image=True, filter_outliers=True)\n",
    "\n",
    "transform, residuals, tps, conf = georefSat.georeference(image, footprint_approx, mask, azimuth, month)\n",
    "\n",
    "if transform is None:\n",
    "    if save_image:\n",
    "        processed_images[img_id] = {\"method\": \"sat\", \"status\": \"failed\", \"reason\": \"no_transform\", \"time\":\"\"}\n",
    "        mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Image successfully geo-referenced\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d54e4dbfca57325"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Verify the image geometry</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid because of: length:20.29\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import src.base.modify_csv as mc\n",
    "import src.georef.snippets.verify_image_geometry as vig\n",
    "\n",
    "transform_fl = transform.flatten()\n",
    "\n",
    "valid_geometry, reason = vig.verify_image_geometry(image, transform_fl)\n",
    "\n",
    "# get datetime\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%d.%m.%Y %H:%M\")\n",
    "\n",
    "\n",
    "if valid_geometry:\n",
    "    print(\"Valid geometry:\", valid_geometry)\n",
    "    if save_image:\n",
    "        processed_images[img_id] = {\"method\": \"sat\", \"status\": \"georeferenced\",\n",
    "                                    \"reason\": \"\", \"time\":\"\", \"date\": date_time_str}\n",
    "        mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "else:\n",
    "    print(\"Invalid because of:\", reason)\n",
    "    if save_image:\n",
    "        processed_images[img_id] = {\"method\": \"sat\", \"status\": \"invalid\",\n",
    "                                    \"reason\": reason, \"time\":\"\", \"date\": date_time_str}\n",
    "        mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Save the data </h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9522, 10139) (9,)\n",
      "POLYGON ((-2084049.7474042203 762921.306125847, -2076725.146616946 759658.4108122545, -2080092.3547890482 751753.1042703891, -2087416.9555763225 755015.9995839816, -2084049.7474042203 762921.306125847))\n",
      "0    CA184832V0118\n",
      "Name: image_id, dtype: object\n",
      "['CA214232V0168' 'CA164432V0027' 'CA183332V0109' 'CA181732V0012'\n",
      " 'CA183332V0136' 'CA182132V0089' 'CA184632V0357' 'CA196232V0038'\n",
      " 'CA184832V0105' 'CA180732V0011' 'CA181632V0103' 'CA181632V0139'\n",
      " 'CA183332V0148' 'CA183332V0135' 'CA182132V0150' 'CA181732V0014'\n",
      " 'CA184632V0356' 'CA183332V0119' 'CA183332V0069' 'CA174532V0013'\n",
      " 'CA183332V0117' 'CA184632V0370' 'CA216032V0031' 'CA214232V0154'\n",
      " 'CA214132V0070' 'CA212432V0069' 'CA183332V0134' 'CA181632V0111'\n",
      " 'CA184632V0369' 'CA207332V0125' 'CA214232V0157' 'CA212432V0074'\n",
      " 'CA216032V0025' 'CA212432V0080' 'CA182232V0034' 'CA184332V0031'\n",
      " 'CA181732V0021' 'CA181332V0083' 'CA183332V0118' 'CA184332V0053'\n",
      " 'CA183332V0080' 'CA181832V0003' 'CA181832V0054' 'CA181832V0002'\n",
      " 'CA183332V0150' 'CA181832V0045' 'CA181232V0072' 'CA182132V0155'\n",
      " 'CA184632V0381' 'CA196632V0033' 'CA183332V0147' 'CA214232V0162'\n",
      " 'CA180132V0123' 'CA182132V0152' 'CA181832V0046' 'CA216632V0291'\n",
      " 'CA181632V0038' 'CA181332V0085' 'CA181332V0082' 'CA182132V0074'\n",
      " 'CA182132V0088' 'CA182132V0147' 'CA183332V0124' 'CA183332V0128'\n",
      " 'CA181732V0016' 'CA212132V0081' 'CA207332V0128' 'CA212332V0015'\n",
      " 'CA181232V0066' 'CA183332V0096' 'CA214232V0165' 'CA182532V0016'\n",
      " 'CA181232V0070' 'CA184332V0079' 'CA181632V0114' 'CA182132V0095'\n",
      " 'CA214232V0122' 'CA184632V0382' 'CA214232V0123' 'CA184632V0349'\n",
      " 'CA214232V0155' 'CA182132V0042' 'CA164432V0028' 'CA212132V0084'\n",
      " 'CA214232V0195' 'CA212432V0065' 'CA214232V0161' 'CA182132V0097'\n",
      " 'CA184832V0103' 'CA214132V0075' 'CA183332V0127' 'CA181332V0139'\n",
      " 'CA184632V0371' 'CA183332V0093' 'CA183332V0120' 'CA180132V0109'\n",
      " 'CA214232V0159' 'CA183332V0087' 'CA216732V0351' 'CA181232V0071'\n",
      " 'CA181632V0110' 'CA214232V0164' 'CA182132V0153' 'CA181232V0055'\n",
      " 'CA183332V0121' 'CA181632V0108' 'CA183332V0067' 'CA184332V0059'\n",
      " 'CA183332V0094' 'CA184632V0367' 'CA182132V0149' 'CA182132V0080'\n",
      " 'CA196632V0068' 'CA214732V0031' 'CA182132V0071' 'CA181332V0120'\n",
      " 'CA214132V0069' 'CA181332V0128' 'CA182132V0078' 'CA183332V0084'\n",
      " 'CA183332V0086' 'CA164432V0070' 'CA214132V0071' 'CA180132V0122'\n",
      " 'CA182532V0015' 'CA183332V0060' 'CA181632V0109' 'CA181732V0017'\n",
      " 'CA182132V0077' 'CA184832V0114' 'CA184332V0069' 'CA183332V0077'\n",
      " 'CA212432V0113' 'CA183332V0089' 'CA181632V0113' 'CA212332V0040'\n",
      " 'CA181632V0034' 'CA184632V0350' 'CA181732V0020' 'CA214232V0166'\n",
      " 'CA183332V0113' 'CA214132V0076' 'CA183332V0133' 'CA181232V0056'\n",
      " 'CA196632V0044' 'CA182432V0010' 'CA182132V0081' 'CA180132V0150'\n",
      " 'CA183332V0068' 'CA181632V0037' 'CA214232V0158' 'CA181232V0076'\n",
      " 'CA214232V0126' 'CA214132V0073' 'CA182132V0151' 'CA182332V0015'\n",
      " 'CA181732V0024' 'CA181332V0130' 'CA183332V0132' 'CA181332V0131'\n",
      " 'CA212132V0082' 'CA182132V0098' 'CA182332V0016' 'CA164432V0024'\n",
      " 'CA182432V0011' 'CA181232V0069' 'CA183332V0085' 'CA216432V0207'\n",
      " 'CA181632V0040' 'CA181232V0065' 'CA181232V0068' 'CA212332V0048'\n",
      " 'CA181732V0013' 'CA214732V0032' 'CA183532V0083' 'CA183332V0123'\n",
      " 'CA183332V0091' 'CA181832V0043' 'CA207332V0131' 'CA181832V0052'\n",
      " 'CA181832V0004' 'CA183332V0153' 'CA182932V0004' 'CA164432V0031'\n",
      " 'CA207432V0162' 'CA181332V0113' 'CA180132V0106' 'CA214232V0167'\n",
      " 'CA164432V0037' 'CA181632V0026' 'CA184732V0036' 'CA214232V0163'\n",
      " 'CA207332V0120' 'CA164432V0036' 'CA181732V0011' 'CA181232V0035'\n",
      " 'CA183332V0125' 'CA184332V0027' 'CA181832V0036' 'CA181832V0039'\n",
      " 'CA216632V0294' 'CA182132V0076' 'CA183332V0099' 'CA212332V0045'\n",
      " 'CA181732V0018' 'CA183332V0082' 'CA181232V0057' 'CA183332V0156'\n",
      " 'CA214132V0074' 'CA174632V0172' 'CA183332V0081' 'CA181832V0056'\n",
      " 'CA182432V0027' 'CA212332V0047' 'CA184332V0068' 'CA184332V0045'\n",
      " 'CA184832V0148' 'CA183332V0114' 'CA214132V0072' 'CA182132V0105'\n",
      " 'CA182132V0096' 'CA181332V0127' 'CA180132V0142' 'CA181232V0063'\n",
      " 'CA180132V0096' 'CA181632V0112' 'CA181632V0039' 'CA183332V0078'\n",
      " 'CA182132V0072' 'CA164432V0068' 'CA181332V0111' 'CA180132V0115'\n",
      " 'CA184632V0324' 'CA212432V0106' 'CA216432V0216' 'CA212432V0061'\n",
      " 'CA181832V0051' 'CA183332V0115' 'CA181732V0025' 'CA183332V0090'\n",
      " 'CA183532V0086' 'CA181232V0027' 'CA181232V0064' 'CA182132V0079'\n",
      " 'CA181832V0048' 'CA174632V0174' 'CA214232V0160' 'CA214232V0128'\n",
      " 'CA183332V0137' 'CA216332V0160' 'CA181832V0038' 'CA214232V0156'\n",
      " 'CA196532V0016' 'CA183332V0079' 'CA184332V0056' 'CA183332V0122'\n",
      " 'CA212432V0067' 'CA182132V0148' 'CA212432V0114' 'CA184632V0317'\n",
      " 'CA182232V0029' 'CA183332V0076' 'CA212332V0034' 'CA181732V0015'\n",
      " 'CA184632V0340' 'CA183332V0146' 'CA181732V0022' 'CA183332V0151'\n",
      " 'CA181532V0041' 'CA181332V0089' 'CA181832V0035' 'CA183332V0116'\n",
      " 'CA182432V0026' 'CA164432V0035' 'CA196832V0142' 'CA183332V0098'\n",
      " 'CA181232V0062' 'CA216432V0218' 'CA183332V0095' 'CA184732V0052'\n",
      " 'CA182132V0073']\n",
      "CA184832V0118 successfully saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.georef.snippets.apply_transform as af\n",
    "import src.georef.snippets.convert_image_to_footprint as citf\n",
    "\n",
    "import src.export.export_geometry as eg\n",
    "\n",
    "# merge tps and conf\n",
    "tps_conf = np.concatenate([tps, conf.reshape(-1, 1), residuals.reshape((-1, 1))], axis=1)\n",
    "\n",
    "# define path to shape file\n",
    "path_shp_file = f\"{output_fld}/sat.shp\"\n",
    "\n",
    "if save_image:\n",
    "    # apply the transform and save geo-referenced tiff\n",
    "    af.apply_transform(image, transform, f\"{output_fld}/sat/{img_id}.tif\")\n",
    "\n",
    "    # save transform and points\n",
    "    np.savetxt(f\"{output_fld}/sat/{img_id}_transform.txt\", transform.reshape(3,3), fmt='%.5f')\n",
    "    np.savetxt(f\"{output_fld}/sat/{img_id}_points.txt\", tps_conf, fmt=['%i', '%i', '%.2f', '%.2f', '%.3f', '%.3f'])\n",
    "\n",
    "print(image.shape, transform.shape)\n",
    "\n",
    "# create a footprint for this image\n",
    "footprint = citf.convert_image_to_footprint(image, transform)\n",
    "\n",
    "print(footprint)\n",
    "\n",
    "# calculate average values\n",
    "# noinspection PyTypeChecker\n",
    "conf_mean: float = np.mean(conf)\n",
    "# noinspection PyTypeChecker\n",
    "residuals_mean: float = np.mean(residuals)\n",
    "\n",
    "# define attributes\n",
    "attributes = {\n",
    "    'image_id': img_id,\n",
    "    'month': month,\n",
    "    'num_tps': tps.shape[0],\n",
    "    'avg_conf': round(conf_mean, 3),\n",
    "    'avg_resi': round(residuals_mean, 3),\n",
    "}\n",
    "\n",
    "attributes = pd.DataFrame.from_dict(attributes, orient='index').T\n",
    "\n",
    "if save_image:\n",
    "    # save footprint to shp file\n",
    "    eg.export_geometry(footprint, path_shp_file,\n",
    "                       attributes=attributes, key_field=\"image_id\",\n",
    "                       overwrite_file=False,\n",
    "                       overwrite_entry=True, attach=True)\n",
    "\n",
    "    print(f\"{img_id} successfully saved\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb3481393df9b76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
