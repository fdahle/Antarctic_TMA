{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa5dd78b3114b43"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_id = \"CA168332V0102\"\n",
    "save_image = False\n",
    "overwrite = False\n",
    "\n",
    "output_fld = \"/data_1/ATM/data_1/georef\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Check if the image is already geo-referenced</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define the path to processed images\n",
    "csv_path = output_fld + \"/sat_processed_images.csv\"\n",
    "\n",
    "if save_image:\n",
    "    # load processed images as dict\n",
    "    processed_images = pd.read_csv(csv_path, delimiter=\";\")\n",
    "    processed_images.set_index('id', inplace=True)\n",
    "    processed_images = processed_images.to_dict(orient='index')\n",
    "\n",
    "    # check if image is already geo-referenced\n",
    "    if processed_images.get(img_id, {}).get('status') == \"georeferenced\" and not overwrite:\n",
    "        print(f\"{img_id} already processed\")\n",
    "        exit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Load Image</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9522, 10137)\n"
     ]
    }
   ],
   "source": [
    "import src.load.load_image as ld\n",
    "\n",
    "path_data_fld = \"/data_1/ATM/data_1/aerial/TMA/downloaded\"\n",
    "\n",
    "# load image to geo-reference\n",
    "image = ld.load_image(path_data_fld + f\"/{img_id}.tif\")\n",
    "\n",
    "print(image.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b318989a3fd394d",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Extract geo-referencing data</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azimuth: 218.1363\n",
      "Month: 0\n",
      "Approx footprint: POLYGON((-2402985.9129472496 1527096.5771034183,-2401315.9828965818 1524969.6129472493,-2403442.9470527507 1523299.6828965815,-2405112.8771034186 1525426.6470527505,-2402985.9129472496 1527096.5771034183))\n"
     ]
    }
   ],
   "source": [
    "import src.base.connect_to_database as ctd\n",
    "import src.base.modify_csv as mc\n",
    "\n",
    "conn = ctd.establish_connection()\n",
    "\n",
    "sql_string = f\"SELECT * FROM images WHERE image_id='{img_id}'\"\n",
    "data = ctd.execute_sql(sql_string, conn)\n",
    "\n",
    "azimuth = data.iloc[0]['azimuth']\n",
    "month = data.iloc[0]['date_month']\n",
    "\n",
    "azimuth = 360 - azimuth + 90\n",
    "\n",
    "print(\"Azimuth:\", azimuth)\n",
    "print(\"Month:\", month)\n",
    "\n",
    "sql_string_approx = f\"SELECT ST_AsText(footprint_approx) AS footprint_approx FROM images_extracted WHERE image_id='{img_id}'\"\n",
    "data_approx = ctd.execute_sql(sql_string_approx, conn)\n",
    "footprint_approx = data_approx.iloc[0]['footprint_approx']\n",
    "\n",
    "print(\"Approx footprint:\",footprint_approx)\n",
    "\n",
    "if footprint_approx is None:\n",
    "    processed_images[img_id] = {\"method\": \"sat\", \"status\": \"missing_data\",\n",
    "                                  \"reason\": \"approx_footprint\", \"time\":\"\"}\n",
    "    mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()\n",
    "\n",
    "elif azimuth is None:\n",
    "    processed_images[img_id] = {\"method\": \"sat\", \"status\": \"missing_data\",\n",
    "                                  \"reason\": \"azimuth\", \"time\":\"\"}\n",
    "    mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "937eb40f9717a45e",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Create Mask</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (None, None), 2: (None, None), 3: (None, None), 4: (None, None)}\n"
     ]
    }
   ],
   "source": [
    "import src.base.create_mask as cm\n",
    "import src.base.modify_csv as mc\n",
    "\n",
    "import src.display.display_images as di\n",
    "\n",
    "sql_string_fid_marks = f\"SELECT * FROM images_fid_points WHERE image_id='{img_id}'\"\n",
    "data_fid_marks = ctd.execute_sql(sql_string_fid_marks, conn)\n",
    "\n",
    "sql_string_extracted = f\"SELECT * FROM images_extracted WHERE image_id='{img_id}'\"\n",
    "data_extracted = ctd.execute_sql(sql_string_extracted, conn)\n",
    "\n",
    "# Get the fid marks for the specific image_id\n",
    "fid_marks_row = data_fid_marks.loc[data_fid_marks['image_id'] == img_id].squeeze()\n",
    "\n",
    "# Create fid mark dict using dictionary comprehension\n",
    "fid_dict = {i: (fid_marks_row[f'fid_mark_{i}_x'], fid_marks_row[f'fid_mark_{i}_y']) for i in range(1, 5)}\n",
    "\n",
    "# get the text boxes of the image\n",
    "text_string = data_extracted.loc[data_extracted['image_id'] == img_id]['text_bbox'].iloc[0]\n",
    "\n",
    "if len(text_string) > 0 and \"[\" not in text_string:\n",
    "    text_string = \"[\" + text_string + \"]\"\n",
    "\n",
    "# create text-boxes list\n",
    "text_boxes = [list(group) for group in eval(text_string.replace(\";\", \",\"))]\n",
    "\n",
    "print(fid_dict)\n",
    "\n",
    "# load the mask\n",
    "mask = cm.create_mask(image, fid_dict, text_boxes, use_default_fiducials=True)\n",
    "\n",
    "if mask is None:\n",
    "    processed_images[img_id] = {\"method\": \"sat\", \"status\": \"missing_data\",\n",
    "                                  \"reason\": \"mask\", \"time\":\"\"}\n",
    "    mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()\n",
    "\n",
    "\n",
    "di.display_images([image, mask])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e495b60f07b88d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Geo-reference the image</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geo-reference image by satellite\n",
      "Adjusted image resolution with zoom-factor (0.0277, 0.0275)\n",
      "Adjusted image resolution with zoom-factor (0.0277, 0.0275)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.29 MiB is allocated by PyTorch, and 14.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.08 MiB is allocated by PyTorch, and 14.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.90 MiB is allocated by PyTorch, and 15.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.77 MiB is allocated by PyTorch, and 15.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.65 MiB is allocated by PyTorch, and 15.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.56 MiB is allocated by PyTorch, and 15.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.49 MiB is allocated by PyTorch, and 15.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.43 MiB is allocated by PyTorch, and 15.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.38 MiB is allocated by PyTorch, and 15.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.34 MiB is allocated by PyTorch, and 15.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.31 MiB is allocated by PyTorch, and 15.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.29 MiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.27 MiB is allocated by PyTorch, and 15.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 30.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.25 MiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.24 MiB is allocated by PyTorch, and 13.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.23 MiB is allocated by PyTorch, and 13.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.22 MiB is allocated by PyTorch, and 13.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.56 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Locate image position\n",
      "  Check tile 1 (Coords: [-2540, -2540], Order 1)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.29 MiB is allocated by PyTorch, and 14.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.08 MiB is allocated by PyTorch, and 14.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.90 MiB is allocated by PyTorch, and 15.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.77 MiB is allocated by PyTorch, and 15.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.65 MiB is allocated by PyTorch, and 15.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.56 MiB is allocated by PyTorch, and 15.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.49 MiB is allocated by PyTorch, and 15.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.43 MiB is allocated by PyTorch, and 15.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.38 MiB is allocated by PyTorch, and 15.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.34 MiB is allocated by PyTorch, and 15.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.31 MiB is allocated by PyTorch, and 15.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.29 MiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.27 MiB is allocated by PyTorch, and 15.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.25 MiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.24 MiB is allocated by PyTorch, and 13.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.23 MiB is allocated by PyTorch, and 13.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.22 MiB is allocated by PyTorch, and 13.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 2 (Coords: [-2540, 0], Order 1)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.29 MiB is allocated by PyTorch, and 14.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.08 MiB is allocated by PyTorch, and 14.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.90 MiB is allocated by PyTorch, and 15.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.77 MiB is allocated by PyTorch, and 15.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.65 MiB is allocated by PyTorch, and 15.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.56 MiB is allocated by PyTorch, and 15.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.49 MiB is allocated by PyTorch, and 15.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.43 MiB is allocated by PyTorch, and 15.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.38 MiB is allocated by PyTorch, and 15.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.34 MiB is allocated by PyTorch, and 15.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.31 MiB is allocated by PyTorch, and 15.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.29 MiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.27 MiB is allocated by PyTorch, and 15.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.25 MiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.24 MiB is allocated by PyTorch, and 13.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.23 MiB is allocated by PyTorch, and 13.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.22 MiB is allocated by PyTorch, and 13.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 3 (Coords: [-2540, 2540], Order 1)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.29 MiB is allocated by PyTorch, and 14.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.08 MiB is allocated by PyTorch, and 14.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.90 MiB is allocated by PyTorch, and 15.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.77 MiB is allocated by PyTorch, and 15.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.65 MiB is allocated by PyTorch, and 15.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.56 MiB is allocated by PyTorch, and 15.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.49 MiB is allocated by PyTorch, and 15.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.43 MiB is allocated by PyTorch, and 15.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.38 MiB is allocated by PyTorch, and 15.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.34 MiB is allocated by PyTorch, and 15.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.31 MiB is allocated by PyTorch, and 15.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.29 MiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.27 MiB is allocated by PyTorch, and 15.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.25 MiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.24 MiB is allocated by PyTorch, and 13.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.23 MiB is allocated by PyTorch, and 13.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.22 MiB is allocated by PyTorch, and 13.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 4 (Coords: [0, -2540], Order 1)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.29 MiB is allocated by PyTorch, and 14.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.08 MiB is allocated by PyTorch, and 14.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.90 MiB is allocated by PyTorch, and 15.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.77 MiB is allocated by PyTorch, and 15.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.65 MiB is allocated by PyTorch, and 15.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.56 MiB is allocated by PyTorch, and 15.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.49 MiB is allocated by PyTorch, and 15.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.43 MiB is allocated by PyTorch, and 15.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.38 MiB is allocated by PyTorch, and 15.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.34 MiB is allocated by PyTorch, and 15.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.31 MiB is allocated by PyTorch, and 15.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.29 MiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.27 MiB is allocated by PyTorch, and 15.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 32.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.25 MiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.24 MiB is allocated by PyTorch, and 13.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.23 MiB is allocated by PyTorch, and 13.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.22 MiB is allocated by PyTorch, and 13.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.94 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 5 (Coords: [0, 2540], Order 1)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.29 MiB is allocated by PyTorch, and 14.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 567.08 MiB is allocated by PyTorch, and 14.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.90 MiB is allocated by PyTorch, and 15.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.77 MiB is allocated by PyTorch, and 15.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.65 MiB is allocated by PyTorch, and 15.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.56 MiB is allocated by PyTorch, and 15.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.49 MiB is allocated by PyTorch, and 15.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.43 MiB is allocated by PyTorch, and 15.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.38 MiB is allocated by PyTorch, and 15.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.34 MiB is allocated by PyTorch, and 15.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.31 MiB is allocated by PyTorch, and 15.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.29 MiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.27 MiB is allocated by PyTorch, and 15.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 34.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.25 MiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.24 MiB is allocated by PyTorch, and 13.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.23 MiB is allocated by PyTorch, and 13.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.22 MiB is allocated by PyTorch, and 13.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.21 MiB is allocated by PyTorch, and 13.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.20 MiB is allocated by PyTorch, and 13.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.19 MiB is allocated by PyTorch, and 13.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 36.06 MiB is free. Process 930370 has 13.67 GiB memory in use. Including non-PyTorch memory, this process has 1.55 GiB memory in use. Of the allocated memory 566.18 MiB is allocated by PyTorch, and 13.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 6 (Coords: [2540, -2540], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 7 (Coords: [2540, 0], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 8 (Coords: [2540, 2540], Order 1)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 9 (Coords: [-5080, -5080], Order 2)\n",
      "  0 points were found in this tile.\n",
      "  Check tile 10 (Coords: [-5080, -2540], Order 2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 8\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeoref\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeoref_sat\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgs\u001B[39;00m\n\u001B[1;32m      5\u001B[0m georefSat \u001B[38;5;241m=\u001B[39m gs\u001B[38;5;241m.\u001B[39mGeorefSatellite(min_tps_final\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m,\n\u001B[1;32m      6\u001B[0m                                enhance_image\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, locate_image\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, tweak_image\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, filter_outliers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 8\u001B[0m transform, residuals, tps, conf \u001B[38;5;241m=\u001B[39m georefSat\u001B[38;5;241m.\u001B[39mgeoreference(image, footprint_approx, mask, azimuth, month)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m save_image:\n",
      "File \u001B[0;32m~/Documents/GitHub/Antarctic_TMA/src/georef/georef_sat.py:175\u001B[0m, in \u001B[0;36mGeorefSatellite.georeference\u001B[0;34m(self, input_image, approx_footprint, mask, angle, month)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;66;03m# locate the image around the approx footprint\u001B[39;00m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocate_image:\n\u001B[0;32m--> 175\u001B[0m     sat, sat_bounds, sat_transform, tps, conf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_perform_locate_image(image, mask, sat, sat_bounds,\n\u001B[1;32m    176\u001B[0m                                                                            sat_transform, tps, conf)\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debug_display_steps \u001B[38;5;129;01mand\u001B[39;00m debug_display_located:\n\u001B[1;32m    179\u001B[0m         style_config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLocated tie-points for geo-referencing\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    180\u001B[0m                         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maxis_marker\u001B[39m\u001B[38;5;124m\"\u001B[39m: debug_display_axes}\n",
      "File \u001B[0;32m~/Documents/GitHub/Antarctic_TMA/src/georef/georef_sat.py:412\u001B[0m, in \u001B[0;36mGeorefSatellite._perform_locate_image\u001B[0;34m(self, img, mask, sat, sat_bounds, sat_transform, tps, conf)\u001B[0m\n\u001B[1;32m    409\u001B[0m sat_bounds_tile[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m=\u001B[39m sat_bounds_tile[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m+\u001B[39m tile[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    411\u001B[0m \u001B[38;5;66;03m# get the satellite image\u001B[39;00m\n\u001B[0;32m--> 412\u001B[0m sat_tile, sat_transform_tile \u001B[38;5;241m=\u001B[39m ls\u001B[38;5;241m.\u001B[39mload_satellite(sat_bounds_tile,\n\u001B[1;32m    413\u001B[0m                                                  return_empty_sat\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sat_tile \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  No satellite image could be found for this tile\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/Antarctic_TMA/src/load/load_satellite.py:104\u001B[0m, in \u001B[0;36mload_satellite\u001B[0;34m(bounds, sat_folder, satellite_type, satellite_crs, month, return_empty_sat)\u001B[0m\n\u001B[1;32m    101\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo satellite images were found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m# merge the satellite files\u001B[39;00m\n\u001B[0;32m--> 104\u001B[0m merged, transform_merged \u001B[38;5;241m=\u001B[39m rasterio\u001B[38;5;241m.\u001B[39mmerge\u001B[38;5;241m.\u001B[39mmerge(mosaic_files)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;66;03m# close the connection to the mosaic files\u001B[39;00m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m mosaic_files:\n",
      "File \u001B[0;32m~/miniconda3/envs/tma_env/lib/python3.11/site-packages/rasterio/merge.py:385\u001B[0m, in \u001B[0;36mmerge\u001B[0;34m(datasets, bounds, res, nodata, dtype, precision, indexes, output_count, resampling, method, target_aligned_pixels, dst_path, dst_kwds)\u001B[0m\n\u001B[1;32m    383\u001B[0m     temp \u001B[38;5;241m=\u001B[39m temp_src[:, : region\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], : region\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m]]\n\u001B[1;32m    384\u001B[0m     temp_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mma\u001B[38;5;241m.\u001B[39mgetmask(temp)\n\u001B[0;32m--> 385\u001B[0m     copyto(region, temp, region_mask, temp_mask, index\u001B[38;5;241m=\u001B[39midx, roff\u001B[38;5;241m=\u001B[39mroff, coff\u001B[38;5;241m=\u001B[39mcoff)\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dst_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dest, output_transform\n",
      "File \u001B[0;32m~/miniconda3/envs/tma_env/lib/python3.11/site-packages/rasterio/merge.py:27\u001B[0m, in \u001B[0;36mcopy_first\u001B[0;34m(merged_data, new_data, merged_mask, new_mask, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m np\u001B[38;5;241m.\u001B[39mlogical_not(new_mask, out\u001B[38;5;241m=\u001B[39mmask)\n\u001B[1;32m     26\u001B[0m np\u001B[38;5;241m.\u001B[39mlogical_and(merged_mask, mask, out\u001B[38;5;241m=\u001B[39mmask)\n\u001B[0;32m---> 27\u001B[0m np\u001B[38;5;241m.\u001B[39mcopyto(merged_data, new_data, where\u001B[38;5;241m=\u001B[39mmask, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import src.base.modify_csv as mc\n",
    "\n",
    "import src.georef.georef_sat as gs\n",
    "\n",
    "georefSat = gs.GeorefSatellite(min_tps_final=25,\n",
    "                               enhance_image=False, locate_image=True, tweak_image=True, filter_outliers=True)\n",
    "\n",
    "transform, residuals, tps, conf = georefSat.georeference(image, footprint_approx, mask, azimuth, month)\n",
    "\n",
    "if transform is None:\n",
    "    if save_image:\n",
    "        processed_images[img_id] = {\"method\": \"sat\", \"status\": \"failed\", \"reason\": \"no_transform\", \"time\":\"\"}\n",
    "        mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()\n",
    "else:\n",
    "    print(\"Image successfully geo-referenced\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d54e4dbfca57325"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Verify the image geometry</h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.95639861e+00 -3.75770740e-01 -2.51805019e+06  4.94863390e-01\n",
      " -1.53037033e+00  1.34998928e+06  0.00000000e+00  0.00000000e+00\n",
      "  1.00000000e+00]\n",
      "Invalid because of: length:62.88\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import src.base.modify_csv as mc\n",
    "import src.georef.snippets.verify_image_geometry as vig\n",
    "\n",
    "transform_fl = transform.flatten()\n",
    "\n",
    "valid_geometry, reason = vig.verify_image_geometry(image, transform_fl)\n",
    "\n",
    "# get datetime\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%d.%m.%Y %H:%M\")\n",
    "\n",
    "\n",
    "if valid_geometry:\n",
    "    print(\"Valid geometry:\", valid_geometry)\n",
    "    if save_image:\n",
    "        processed_images[img_id] = {\"method\": \"sat\", \"status\": \"georeferenced\",\n",
    "                                    \"reason\": \"\", \"time\":\"\", \"date\": date_time_str}\n",
    "        mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "else:\n",
    "    print(\"Invalid because of:\", reason)\n",
    "    if save_image:\n",
    "        processed_images[img_id] = {\"method\": \"sat\", \"status\": \"invalid\",\n",
    "                                    \"reason\": reason, \"time\":\"\", \"date\": date_time_str}\n",
    "        mc.modify_csv(csv_path, img_id, \"add\", processed_images[img_id], overwrite=True)\n",
    "    exit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Save the data </h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9522, 10139) (9,)\n",
      "POLYGON ((-2084049.7474042203 762921.306125847, -2076725.146616946 759658.4108122545, -2080092.3547890482 751753.1042703891, -2087416.9555763225 755015.9995839816, -2084049.7474042203 762921.306125847))\n",
      "0    CA184832V0118\n",
      "Name: image_id, dtype: object\n",
      "['CA214232V0168' 'CA164432V0027' 'CA183332V0109' 'CA181732V0012'\n",
      " 'CA183332V0136' 'CA182132V0089' 'CA184632V0357' 'CA196232V0038'\n",
      " 'CA184832V0105' 'CA180732V0011' 'CA181632V0103' 'CA181632V0139'\n",
      " 'CA183332V0148' 'CA183332V0135' 'CA182132V0150' 'CA181732V0014'\n",
      " 'CA184632V0356' 'CA183332V0119' 'CA183332V0069' 'CA174532V0013'\n",
      " 'CA183332V0117' 'CA184632V0370' 'CA216032V0031' 'CA214232V0154'\n",
      " 'CA214132V0070' 'CA212432V0069' 'CA183332V0134' 'CA181632V0111'\n",
      " 'CA184632V0369' 'CA207332V0125' 'CA214232V0157' 'CA212432V0074'\n",
      " 'CA216032V0025' 'CA212432V0080' 'CA182232V0034' 'CA184332V0031'\n",
      " 'CA181732V0021' 'CA181332V0083' 'CA183332V0118' 'CA184332V0053'\n",
      " 'CA183332V0080' 'CA181832V0003' 'CA181832V0054' 'CA181832V0002'\n",
      " 'CA183332V0150' 'CA181832V0045' 'CA181232V0072' 'CA182132V0155'\n",
      " 'CA184632V0381' 'CA196632V0033' 'CA183332V0147' 'CA214232V0162'\n",
      " 'CA180132V0123' 'CA182132V0152' 'CA181832V0046' 'CA216632V0291'\n",
      " 'CA181632V0038' 'CA181332V0085' 'CA181332V0082' 'CA182132V0074'\n",
      " 'CA182132V0088' 'CA182132V0147' 'CA183332V0124' 'CA183332V0128'\n",
      " 'CA181732V0016' 'CA212132V0081' 'CA207332V0128' 'CA212332V0015'\n",
      " 'CA181232V0066' 'CA183332V0096' 'CA214232V0165' 'CA182532V0016'\n",
      " 'CA181232V0070' 'CA184332V0079' 'CA181632V0114' 'CA182132V0095'\n",
      " 'CA214232V0122' 'CA184632V0382' 'CA214232V0123' 'CA184632V0349'\n",
      " 'CA214232V0155' 'CA182132V0042' 'CA164432V0028' 'CA212132V0084'\n",
      " 'CA214232V0195' 'CA212432V0065' 'CA214232V0161' 'CA182132V0097'\n",
      " 'CA184832V0103' 'CA214132V0075' 'CA183332V0127' 'CA181332V0139'\n",
      " 'CA184632V0371' 'CA183332V0093' 'CA183332V0120' 'CA180132V0109'\n",
      " 'CA214232V0159' 'CA183332V0087' 'CA216732V0351' 'CA181232V0071'\n",
      " 'CA181632V0110' 'CA214232V0164' 'CA182132V0153' 'CA181232V0055'\n",
      " 'CA183332V0121' 'CA181632V0108' 'CA183332V0067' 'CA184332V0059'\n",
      " 'CA183332V0094' 'CA184632V0367' 'CA182132V0149' 'CA182132V0080'\n",
      " 'CA196632V0068' 'CA214732V0031' 'CA182132V0071' 'CA181332V0120'\n",
      " 'CA214132V0069' 'CA181332V0128' 'CA182132V0078' 'CA183332V0084'\n",
      " 'CA183332V0086' 'CA164432V0070' 'CA214132V0071' 'CA180132V0122'\n",
      " 'CA182532V0015' 'CA183332V0060' 'CA181632V0109' 'CA181732V0017'\n",
      " 'CA182132V0077' 'CA184832V0114' 'CA184332V0069' 'CA183332V0077'\n",
      " 'CA212432V0113' 'CA183332V0089' 'CA181632V0113' 'CA212332V0040'\n",
      " 'CA181632V0034' 'CA184632V0350' 'CA181732V0020' 'CA214232V0166'\n",
      " 'CA183332V0113' 'CA214132V0076' 'CA183332V0133' 'CA181232V0056'\n",
      " 'CA196632V0044' 'CA182432V0010' 'CA182132V0081' 'CA180132V0150'\n",
      " 'CA183332V0068' 'CA181632V0037' 'CA214232V0158' 'CA181232V0076'\n",
      " 'CA214232V0126' 'CA214132V0073' 'CA182132V0151' 'CA182332V0015'\n",
      " 'CA181732V0024' 'CA181332V0130' 'CA183332V0132' 'CA181332V0131'\n",
      " 'CA212132V0082' 'CA182132V0098' 'CA182332V0016' 'CA164432V0024'\n",
      " 'CA182432V0011' 'CA181232V0069' 'CA183332V0085' 'CA216432V0207'\n",
      " 'CA181632V0040' 'CA181232V0065' 'CA181232V0068' 'CA212332V0048'\n",
      " 'CA181732V0013' 'CA214732V0032' 'CA183532V0083' 'CA183332V0123'\n",
      " 'CA183332V0091' 'CA181832V0043' 'CA207332V0131' 'CA181832V0052'\n",
      " 'CA181832V0004' 'CA183332V0153' 'CA182932V0004' 'CA164432V0031'\n",
      " 'CA207432V0162' 'CA181332V0113' 'CA180132V0106' 'CA214232V0167'\n",
      " 'CA164432V0037' 'CA181632V0026' 'CA184732V0036' 'CA214232V0163'\n",
      " 'CA207332V0120' 'CA164432V0036' 'CA181732V0011' 'CA181232V0035'\n",
      " 'CA183332V0125' 'CA184332V0027' 'CA181832V0036' 'CA181832V0039'\n",
      " 'CA216632V0294' 'CA182132V0076' 'CA183332V0099' 'CA212332V0045'\n",
      " 'CA181732V0018' 'CA183332V0082' 'CA181232V0057' 'CA183332V0156'\n",
      " 'CA214132V0074' 'CA174632V0172' 'CA183332V0081' 'CA181832V0056'\n",
      " 'CA182432V0027' 'CA212332V0047' 'CA184332V0068' 'CA184332V0045'\n",
      " 'CA184832V0148' 'CA183332V0114' 'CA214132V0072' 'CA182132V0105'\n",
      " 'CA182132V0096' 'CA181332V0127' 'CA180132V0142' 'CA181232V0063'\n",
      " 'CA180132V0096' 'CA181632V0112' 'CA181632V0039' 'CA183332V0078'\n",
      " 'CA182132V0072' 'CA164432V0068' 'CA181332V0111' 'CA180132V0115'\n",
      " 'CA184632V0324' 'CA212432V0106' 'CA216432V0216' 'CA212432V0061'\n",
      " 'CA181832V0051' 'CA183332V0115' 'CA181732V0025' 'CA183332V0090'\n",
      " 'CA183532V0086' 'CA181232V0027' 'CA181232V0064' 'CA182132V0079'\n",
      " 'CA181832V0048' 'CA174632V0174' 'CA214232V0160' 'CA214232V0128'\n",
      " 'CA183332V0137' 'CA216332V0160' 'CA181832V0038' 'CA214232V0156'\n",
      " 'CA196532V0016' 'CA183332V0079' 'CA184332V0056' 'CA183332V0122'\n",
      " 'CA212432V0067' 'CA182132V0148' 'CA212432V0114' 'CA184632V0317'\n",
      " 'CA182232V0029' 'CA183332V0076' 'CA212332V0034' 'CA181732V0015'\n",
      " 'CA184632V0340' 'CA183332V0146' 'CA181732V0022' 'CA183332V0151'\n",
      " 'CA181532V0041' 'CA181332V0089' 'CA181832V0035' 'CA183332V0116'\n",
      " 'CA182432V0026' 'CA164432V0035' 'CA196832V0142' 'CA183332V0098'\n",
      " 'CA181232V0062' 'CA216432V0218' 'CA183332V0095' 'CA184732V0052'\n",
      " 'CA182132V0073']\n",
      "CA184832V0118 successfully saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.georef.snippets.apply_transform as af\n",
    "import src.georef.snippets.convert_image_to_footprint as citf\n",
    "\n",
    "import src.export.export_geometry as eg\n",
    "\n",
    "# merge tps and conf\n",
    "tps_conf = np.concatenate([tps, conf.reshape(-1, 1), residuals.reshape((-1, 1))], axis=1)\n",
    "\n",
    "# define path to shape file\n",
    "path_shp_file = f\"{output_fld}/sat.shp\"\n",
    "\n",
    "if save_image:\n",
    "    # apply the transform and save geo-referenced tiff\n",
    "    af.apply_transform(image, transform, f\"{output_fld}/sat/{img_id}.tif\")\n",
    "\n",
    "    # save transform and points\n",
    "    np.savetxt(f\"{output_fld}/sat/{img_id}_transform.txt\", transform.reshape(3,3), fmt='%.5f')\n",
    "    np.savetxt(f\"{output_fld}/sat/{img_id}_points.txt\", tps_conf, fmt=['%i', '%i', '%.2f', '%.2f', '%.3f', '%.3f'])\n",
    "\n",
    "print(image.shape, transform.shape)\n",
    "\n",
    "# create a footprint for this image\n",
    "footprint = citf.convert_image_to_footprint(image, transform)\n",
    "\n",
    "print(footprint)\n",
    "\n",
    "# calculate average values\n",
    "# noinspection PyTypeChecker\n",
    "conf_mean: float = np.mean(conf)\n",
    "# noinspection PyTypeChecker\n",
    "residuals_mean: float = np.mean(residuals)\n",
    "\n",
    "# define attributes\n",
    "attributes = {\n",
    "    'image_id': img_id,\n",
    "    'month': month,\n",
    "    'num_tps': tps.shape[0],\n",
    "    'avg_conf': round(conf_mean, 3),\n",
    "    'avg_resi': round(residuals_mean, 3),\n",
    "}\n",
    "\n",
    "attributes = pd.DataFrame.from_dict(attributes, orient='index').T\n",
    "\n",
    "if save_image:\n",
    "    # save footprint to shp file\n",
    "    eg.export_geometry(footprint, path_shp_file,\n",
    "                       attributes=attributes, key_field=\"image_id\",\n",
    "                       overwrite_file=False,\n",
    "                       overwrite_entry=True, attach=True)\n",
    "\n",
    "    print(f\"{img_id} successfully saved\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb3481393df9b76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
